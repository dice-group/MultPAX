{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to compute F1-Embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision: how many matched keyphrases with the ground-truth in the output \n",
    "# recall: how many matched keyphrases in the output w.r.t all ground-truth keyphrases\n",
    "\n",
    "#todo:- get word embedding from a pre-trained model (e.g. BERT)\n",
    "# compute semantic similarity match between two words if cosine_sim > 5.0 ==> consider as a matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation with test data\n",
    "\n",
    "groundtruth_keyphrases= [\n",
    "'complex biological processes',\n",
    "'robust model-order reduction',\n",
    "'high dimensional nonlinear partial differential equation model',\n",
    "'nonlinear distributed parameter model',\n",
    "'pilot-scale BNR activated sludge plant',\n",
    "'state-space model',\n",
    "'singular perturbation approximation balanced truncating technique',\n",
    "'modelling errors',\n",
    "'controller design',\n",
    "'Hankel singular values',\n",
    "'biological nutrient removal activated sludge processes',\n",
    "'biotechnology',\n",
    "'control system synthesis',\n",
    "'nonlinear control systems',\n",
    "'nonlinear differential equations',\n",
    "'partial differential equations',\n",
    "'reduced order systems',\n",
    "'robust control',\n",
    "'singularly perturbed systems',\n",
    "'state-space methods',\n",
    "'water treatment'\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "predicted_keyphrases=[\n",
    "'model order reduction', \n",
    "'reduction complex biological', \n",
    "'biological process based', \n",
    "'model complex biological', \n",
    "'pde model complex', \n",
    "'model process', \n",
    "'order reduction complex',\n",
    "'reduce original model', \n",
    "'pde model presented', \n",
    "'biological processes'\n",
    "'organic_process', \n",
    "'life_processes',\n",
    "'life_function',\n",
    "'biological_process', \n",
    "'process_(biological)',\n",
    "'physiological_process'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files by the id (fname)- pair reading from the two folders.\n",
    "with open('ground-truth file path') as fileIn:\n",
    "    groundtruth_keyphrases = fileIn.readlines()\n",
    "    \n",
    "    fileIn.close()\n",
    "    \n",
    "with open('predicted-keyphrases file path') as fileIn:\n",
    "    predicted_keyphrases = fileIn.readlines()\n",
    "    \n",
    "    fileIn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# # init embedding\n",
    "# embedding = TransformerDocumentEmbeddings('bert-base-uncased')\n",
    "\n",
    "groundtruth_embedding= model.encode(groundtruth_keyphrases, convert_to_tensor=True)\n",
    "keyphrase_embedding = model.encode(predicted_keyphrases, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_score = util.pytorch_cos_sim(keyphrase_embedding, groundtruth_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of similar terms:  14\n",
      "Recall:  0.667\n",
      "Precision:  0.933\n",
      "F1:  0.778\n"
     ]
    }
   ],
   "source": [
    "num_of_Similar=0 # number of similar keyphrases\n",
    "\n",
    "for similarty_score in cosine_score:\n",
    "    if any(similarity_threshould > 0.5 for similarity_threshould in similarty_score):\n",
    "        num_of_Similar+=1\n",
    "        \n",
    "recall= num_of_Similar/len(groundtruth_keyphrases)\n",
    "precision= num_of_Similar/len(predicted_keyphrases)\n",
    "\n",
    "F1= 2*(recall*precision)/(recall+precision)\n",
    "\n",
    "print ('number of similar terms: ',num_of_Similar)\n",
    "print ('Recall: ',\"%.3f\"%recall)\n",
    "print('Precision: ', \"%.3f\"%precision)\n",
    "print ('F1: ', \"%.3f\"%F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
