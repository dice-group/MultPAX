{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Steps: \n",
    "# -----:\n",
    "\n",
    "# + get word embedding, for keyphrase (more than one word), take average of word embeddings\n",
    "# + compute similarity score (e.g. using cosine) and find the max similarity score between a predicte keyphrase w.r.t all gold standard keyphrases\n",
    "# + GM (pred, gold)= um of all similarity scores / number of predicted keyprhases .. Eq. (14)--> https://arxiv.org/abs/1910.07897\n",
    "\n",
    "# Futher, we can compute symmetric score\n",
    "# + T = GM (gold, pred) + GM (pred, gold)\n",
    "# + symmGM(pred, gold)= T/2\n",
    "\n",
    "# >> Finally Embedding-based GreedyMatching\n",
    "\n",
    "# GM (pred, gold)= sum of scores (pred_i, gold) / (p+alpha . max (0, g-p))\n",
    "# GM (gold, pred)= sum of scores (gold_i, pred) / (g+beta . max (0, p-g))\n",
    "# T = GM (pred, gold) + GM (gold, pred)\n",
    "# G(pred, gold)= T/2\n",
    "\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import glob\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_matching(list_A, List_B, x): \n",
    "    \n",
    "    sum_of_similarities= 0\n",
    "    \n",
    "    for keyphrase in list_A:         \n",
    "        sum_of_similarities+= torch.max(util.pytorch_cos_sim(keyphrase, List_B))\n",
    "               \n",
    "    GM= sum_of_similarities / (len(list_A)+ x * max(0, len(list_A)-len(List_B)))\n",
    "    \n",
    "    return GM\n",
    "\n",
    "\n",
    "def similarty_score(list_A, List_B, alpha=1, beta=1):     \n",
    "    T= greedy_matching(list_A, List_B, x= alpha)+ greedy_matching(List_B,list_A, x= beta)\n",
    "    score= T/2\n",
    "    return round(score.item(), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_writer = csv.writer(open('./Output/GreedyMatching.csv', 'w', encoding='UTF8', newline=''), delimiter='\\t')\n",
    "file_writer.writerow(['id', 'greedMatching'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cosine similarity scores based on embeddings between two lists.\n",
    "\n",
    "groundTruth_path= '../Inspec/keys/*.key'\n",
    "predicted_path='./Output/Ranking/'\n",
    "\n",
    "fNames= glob.glob(groundTruth_path)\n",
    "\n",
    "for file in fNames:\n",
    "    \n",
    "    with open(file) as fileIn:\n",
    "        groundtruth_keyphrases = fileIn.readlines()        \n",
    "        groundtruth_embedding= model.encode(groundtruth_keyphrases, convert_to_tensor=True)                \n",
    "        fileIn.close()\n",
    "\n",
    "    fileName= file.split('/')[-1][:-3]+'txt'\n",
    "    \n",
    "    with open(predicted_path+fileName) as fileIn:\n",
    "        predicted_keyphrases = fileIn.readlines()        \n",
    "        predicted_keyphrases= [keyphrase.replace('\\n', '') for keyphrase in predicted_keyphrases]        \n",
    "        keyphrase_embedding = model.encode(predicted_keyphrases, convert_to_tensor=True)\n",
    "        \n",
    "        \n",
    "    score=similarty_score(keyphrase_embedding, groundtruth_embedding, 1, 1) # set hyper-parameters alpha=1, beta=1 \n",
    "    \n",
    "    #save evaluation results into csv file    \n",
    "    file_writer.writerow([fileName[:-4], score])\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
