{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "Path(\"./Output/\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"./Output/Evaluation/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_writer = csv.writer(open('./Output/Inspec-PorterStemming.csv', 'w', encoding='UTF8', newline=''), delimiter='\\t')\n",
    "file_writer.writerow(['Top@', 'precision', 'recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get id of the test documents from the benchmarking path (../ake-datasets/../test)\n",
    "# Modify the path (i.e., redirect to the ground-truth folder) to geth the gold standard keywords\n",
    "test_docs= glob.glob('../ake-datasets/datasets/Inspec/test/*.xml')\n",
    "test_docs= ['../Inspec/keys/'+doc.split('/')[-1][:-3]+'key' for doc in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extact Matching ###\n",
    "\n",
    "def extactMatcing(predictKeyphrases, groundKeyphrases):\n",
    "    \n",
    "    # compute porter stemming for predicted and groundtruth keyphrases    \n",
    "    predKeyphrases_list= []\n",
    "    for key in predictKeyphrases:\n",
    "        predKeyphrases_list.append([ps.stem(k) for k in key.split()])\n",
    "        \n",
    "    groundKeyphrases_list= []\n",
    "    for key in groundKeyphrases:\n",
    "        groundKeyphrases_list.append([ps.stem(k) for k in key.split()])    \n",
    "    \n",
    "    exactMatch=True\n",
    "    correctCount=0\n",
    "                                   \n",
    "    for predKey in predKeyphrases_list: \n",
    "                                   \n",
    "        for goldKey in groundKeyphrases_list: \n",
    "            if len(predKey) != len(goldKey):\n",
    "                continue\n",
    "                                   \n",
    "            for pred_w, gold_w in zip(predKey,goldKey): \n",
    "                    if pred_w !=gold_w:\n",
    "                        exactMatch=False\n",
    "                        break\n",
    "        if exactMatch:\n",
    "            correctCount+=1                        \n",
    "                \n",
    "    precision= correctCount/len(predictKeyphrases)\n",
    "    recall = correctCount /len(groundKeyphrases)\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_path='./Output/AKE/' # change this path to compute F1 evaluation based on exact-matching\n",
    "\n",
    "#--- compute average recall, precision, F1 based on instance --#\n",
    "num_of_sample = len(test_docs) # numbe of documents\n",
    "sum_of_recall=0\n",
    "sum_of_precision=0\n",
    "\n",
    "#--- K= { 5, 10} ---#\n",
    "k= 10\n",
    "\n",
    "sum_of_recall=0\n",
    "sum_of_precision=0\n",
    "\n",
    "file_counts=0\n",
    "\n",
    "for file in test_docs:\n",
    "    \n",
    "    # reading the ground-truth keyphrases as a list\n",
    "    with open(file) as fileIn:\n",
    "        groundtruth_keyphrases = fileIn.readlines()[:k]\n",
    "        groundtruth_keyphrases= [keyphrase.replace('\\n', '').replace('\\t','') for keyphrase in groundtruth_keyphrases]\n",
    "    fileIn.close()\n",
    "\n",
    "    # reading the predicted keyphrases as a list\n",
    "    fileName= file.split('/')[-1][:-3]+'txt'\n",
    "    predictKey_file = Path(predicted_path+fileName)\n",
    "    \n",
    "    if not predictKey_file.is_file():\n",
    "        continue\n",
    "    \n",
    "    file_counts+=1\n",
    "    with open(predictKey_file) as fileIn:\n",
    "        predicted_keyphrases = fileIn.readlines()[:k]\n",
    "        predicted_keyphrases= [keyphrase.replace('\\n', '') for keyphrase in predicted_keyphrases]\n",
    "            \n",
    "    #compute precision and recall-based on exact matching\n",
    "    precision, recall= extactMatcing(predicted_keyphrases, groundtruth_keyphrases)\n",
    "    \n",
    "    sum_of_recall+= recall\n",
    "    sum_of_precision+= precision\n",
    "    \n",
    "avg_recall= sum_of_recall/num_of_sample\n",
    "avg_precision= sum_of_precision/num_of_sample\n",
    "\n",
    "F1= 2*(avg_recall*avg_precision)/(avg_precision+avg_recall)\n",
    "\n",
    "print (['Top@'+str(k), round(avg_precision, 3), round(avg_recall,3), round(F1, 3)])\n",
    "#save evaluation results into csv file    \n",
    "file_writer.writerow(['Top@'+str(k), round(avg_precision, 3), round(avg_recall,3), round(F1, 3)]) \n",
    "file_writer.flush()           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
